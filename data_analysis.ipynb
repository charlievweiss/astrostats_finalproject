{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for loading data and beginning machine learning\n",
    "\n",
    "Research: \n",
    "- journal: http://iraj.in/journal/journal_file/journal_pdf/1-10-139036756510-16.pdf\n",
    "    - Overview of supervised learning algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load from data file\n",
    "\n",
    "path = \"processed_images/\"\n",
    "name = \"data.txt\"\n",
    "filename = path + name\n",
    "\n",
    "data = pd.read_csv(filename, delimiter = \",\", engine='python')\n",
    "\n",
    "# don't need these right now...\n",
    "#img_nums = data.loc[:,'img_num']\n",
    "#X = data.loc[:,'x']\n",
    "#Y = data.loc[:,'y']\n",
    "#labels = data.loc[:,'label']\n",
    "\n",
    "#coordinates = []\n",
    "#for i in range(0, len(X)):\n",
    "#    coordinates.append([X[0], Y[0]])\n",
    "\n",
    "images = []\n",
    "\n",
    "for i in range(0, len(data)):\n",
    "    img_num = img_nums[i]\n",
    "    img_file = \"{}.png\".format(img_num)\n",
    "    img_name = path+img_file\n",
    "\n",
    "    img = cv2.imread(img_name)\n",
    "    images.append(img)\n",
    "    \n",
    "# add images to dataframe for ease later\n",
    "data['image'] = pd.Series(images, index=data.index)\n",
    "\n",
    "# CHECK:\n",
    "#img = data['image'].iloc[0]\n",
    "#plt.imshow(img)\n",
    "#print(data)\n",
    "#print(labels)\n",
    "#print(len(images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## split into training and testing sets\n",
    "num_samples = data.shape[0]\n",
    "training_size = .5\n",
    "testing_size = 1 - training_size\n",
    "\n",
    "# generate random sample from data for training set, and make testing set all else\n",
    "msk = np.random.rand(num_samples) < training_size\n",
    "training_data = data[msk]\n",
    "testing_data = data[~msk]\n",
    "\n",
    "#print(training_set)\n",
    "#print(testing_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process data with Principle Component Analysis\n",
    "to extract meaningful features from data. Images are too big!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(285,)\n",
      "<class 'numpy.ndarray'>\n",
      "[[[  0   0   0]\n",
      "  [  0   0   0]\n",
      "  [  0   0   0]\n",
      "  [  0   0   0]\n",
      "  [  0   0   0]\n",
      "  [  0   0   0]]\n",
      "\n",
      " [[  0   0   0]\n",
      "  [  0   0   0]\n",
      "  [  0   0   0]\n",
      "  [  0   0   0]\n",
      "  [  0   0   0]\n",
      "  [  0   0   0]]\n",
      "\n",
      " [[ 33  32  33]\n",
      "  [ 16  20  16]\n",
      "  [ 74  73  74]\n",
      "  [ 74  77  74]\n",
      "  [  0   0   0]\n",
      "  [ 33  36  33]]\n",
      "\n",
      " [[  8  12   8]\n",
      "  [ 33  36  33]\n",
      "  [ 41  45  41]\n",
      "  [ 41  40  41]\n",
      "  [ 41  40  41]\n",
      "  [ 33  40  41]]\n",
      "\n",
      " [[ 49  49  49]\n",
      "  [ 33  36  33]\n",
      "  [ 58  61  58]\n",
      "  [ 66  69  66]\n",
      "  [ 58  65  66]\n",
      "  [ 49  53  49]]\n",
      "\n",
      " [[ 41  45  41]\n",
      "  [ 33  32  33]\n",
      "  [156 154 156]\n",
      "  [255 255 255]\n",
      "  [ 41  45  41]\n",
      "  [ 58  61  58]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mess with images\n",
    "training_images = np.array(training_data.loc[:,'image'])#.tolist()\n",
    "print(training_images.shape)\n",
    "img = training_images[0]\n",
    "print(type(img[0]))\n",
    "print(training_images[0:5][0])\n",
    "\n",
    "\n",
    "#img = training_images.iloc[2]\n",
    "#pca = PCA(n_components=1)\n",
    "#pca.fit(training_images)\n",
    "\n",
    "#print(training_images.shape)\n",
    "#print(training_images[0])\n",
    "#plt.imshow(img)\n",
    "#print(training_images.iloc[2])\n",
    "#print(img.shape)\n",
    "\n",
    "type(training_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1 -1]\n",
      " [-2 -1]\n",
      " [-3 -2]\n",
      " [ 1  1]\n",
      " [ 2  1]\n",
      " [ 3  2]]\n"
     ]
    }
   ],
   "source": [
    "test = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])\n",
    "test.shape\n",
    "print(test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
